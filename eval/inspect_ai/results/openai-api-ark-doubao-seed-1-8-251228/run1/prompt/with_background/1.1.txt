PROBLEM DESCRIPTION:
You will be provided with problem steps along with background knowledge necessary for solving the problem. Your task will be to develop a Python solution focused on the next step of the problem-solving process.

PROBLEM STEPS AND FUNCTION CODE:
Here, you'll find the Python code for the initial steps of the problem-solving process. This code is integral to building the solution.



NEXT STEP - PROBLEM STEP AND FUNCTION HEADER:
This part will describe the next step in the problem-solving process. A function header will be provided, and your task is to develop the Python code for this next step based on the provided description and function header.

Create a function to solve the linear system $\mathbf{A} \mathbf{x} = \mathbf{b}$ using the conjugate gradient method. This function takes a matrix $\mathbf{A}$ and a vector $\mathbf{b}$ as inputs.
Background:
The conjugate gradient method finds a unique minimizer of the quadratic form
\begin{equation}
f(\mathbf{x})=\frac{1}{2} \mathbf{x}^{\top} \mathbf{A} \mathbf{x}-\mathbf{x}^{\top} \mathbf{A} \mathbf{x}, \quad \mathbf{x} \in \mathbf{R}^n .
\end{equation}
The unique minimizer is evident due to the symmetry and positive definiteness of its Hessian matrix of second derivatives, and the fact that the minimizer, satisfying $\nabla f(x)=\mathbf{A x}-\mathbf{b}=0$, solves the initial problem.

This implies choosing the initial basis vector $p_0$ as the negation of the gradient of $f$ at $x=x_0$. The gradient of ff is $Ax−b$. Beginning with an initial guess $x_0$, this implies setting $p_0=b−Ax_0$. The remaining basis vectors will be conjugate to the gradient, hence the name "conjugate gradient method". Note that $p_0$ is also the residual generated by this initial algorithm step.

The conjugation constraint is similar to an orthonormality constraint, which allows us to view the algorithm as an instance of Gram-Schmidt orthonormalization. This leads to the following expression:
$$
\mathbf{p}_k=\mathbf{r}_k-\sum_{i<k} \frac{\mathbf{p}_i^{\top} \mathbf{A} \mathbf{p}_k}{\mathbf{p}_i^{\top} \mathbf{A} \mathbf{p}_i} \mathbf{p}_i
$$
The next optimal location is therefore given by
$$
\mathbf{x}_{k+1}=\mathbf{x}_k+\alpha_k \mathbf{p}_k
$$
with
$$
\alpha_k=\frac{\mathbf{p}_k^{\top}\left(\mathbf{b}-\mathbf{A} \mathbf{x}_k\right)}{\mathbf{p}_k^{\top} \mathbf{A} \mathbf{p}_k}=\frac{\mathbf{p}_k^{\top} \mathbf{r}_k}{\mathbf{p}_k^{\top} \mathbf{A} \mathbf{p}_k},
$$

def cg(A, b, x, tol):
    '''Inputs:
    A : Matrix, 2d array size M * M
    b : Vector, 1d array size M
    x : Initial guess vector, 1d array size M
    tol : tolerance, float
    Outputs:
    x : solution vector, 1d array size M
    '''

    return x

DEPENDENCIES:
Use only the following dependencies in your solution. Do not include these dependencies at the beginning of your code.

import numpy as np

RESPONSE GUIDELINES:
Now, based on the instructions and information provided above, write the complete and executable Python program for the next step in a single block.
Your response should focus exclusively on implementing the solution for the next step, adhering closely to the specified function header and the context provided by the initial steps.
Your response should NOT include the dependencies and functions of all previous steps. If your next step function calls functions from previous steps, please make sure it uses the headers provided without modification.
DO NOT generate EXAMPLE USAGE OR TEST CODE in your response. Please make sure your response python code in format of ```python```.